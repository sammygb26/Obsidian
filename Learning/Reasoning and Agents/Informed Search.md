We have already seen [[Search]] based strategies like **BFS**, **DFS** and **IDS** these are **uninformed** searches. **Informed** means we have vales assigned to nodes telling us which ones are the most desirable. The way we get these scores is with **domain knowledge**. So it is like [[Tree Search]] accept the frontier is ordered in some way in terms of desirability.

## Best First Search
This is like general tree search or graph search. We will use a function for each node that is an **estimate** of desirability. We will expand the desirable unexpanded node which usually has **lowest** evaluation. Even though we are maximizing a value function we are not Utility-[[Agents]].

**Heuristic** -> Any method believed or proven will be useful for finding a solution to a problem. So this doesn't guarantee the best soliton it just helps find one. It may not help so the worst case time will be the same. However the average will be better.

An example would be in the example of finding a path from Arad to Bucharest we would have a distance heuristic to Bucharest. Note this doesn't necessarily work say if a city was close but there wasn't a path onwards.
![[Pasted image 20220126100512.png]]

#### Greedy best-first search
We have an evaluation function $f(n)=h(n)$ (heuristic). The estimated cost of cheapest path from a node to the goal state. **Greedy** best-first-search expands the node that appears closest to the goal (lowest heuristic). For example with the example above we would take the node with the lowest distance to Bucharest. 

**Properties** -> *Complete*, no it could get stuck in an infinite sequence or loop. *Time complexity* would in the worst case be $O(b^m)$ as in the worst case it is the same, however the average case is better as $m$ is the depth we explore to which can be much smaller with a good heuristic. *Space complexity* would be $O(b^m)$ as we keep all nodes in memory as we explore in a random way and we can explore all levels before returning. *Optimal*, no since we will find a solution no necessarily the best as our heuristic could mislead us.

#### A* Search
This is the gold standard in pathfinding problems. In this the evaluation function is $f(n)=g(n)+h(n)$ where $g$ is the cost to reach $n$ and $h$ is the heuristic. So $g$ is the length to us and $h$ is the estimated distance to the goal. An important point here is the goal can be on the frontier but we won't expand it since its *evaluation function* value is lower than other nodes, seen below for our example

![[Pasted image 20220211223002.png]]

##### Heuristics
A* allows us to test for a god heurist. A **heuristic** is **admissible** if for every node n $h(n)\le h^*(n)$ where $h^*(n)$ is the true cost to reach the goal from $n$. This type of heuristic means A* will always find the most optimal solution (if we never overestimate the distance to the goal). This is why straight line distance works since it is always less than or equal to the distance to the goal.

**Proof** 
If some **suboptimal** goal $G_2$ has been generated in the frontier. Let $n$ be an unexpanded node in the frontier such that $n$ is on the **shortest path** to an **optimal** goal $G$. We know $f(G_2)=g(G_2)$ since the final heuristic will be 0. But we know $g(G_2)>g(G)$ since $G_2$ is suboptimal. Again since $G$ is a goal state $f(G)=g(G)$ so $f(G_2)>f(G)$ that is the evaluation function for the true goal must be smaller. Since all nodes on the path to $G$ will have a $f(n)\le f(G)$  since $g(n)+h(n)\le g(n)+h^*(n)$ (since $h$ is admissible) then $f(n)<f(G_2)$ so we will find $G$ before we finish at $G_2$.
![[Pasted image 20220126104659.png]]

A heuristic is **consistent** if for every node $n$ every successor $n'$ of $n$ generated by an action $a$, $h(n)\le c(n,a,n')+h(n')$ that is  our estimated cost is always smaller than the the cost taking into account children. Then we can show
$$
f(n')=g(n')+h(n')=g(n)+c(n,a,n')+h(n')\ge g(n)+h(n)=f(n)
$$
So $f(n')\ge f(n)$ for all $n$. If this is the case for a heuristic A* using **graph search** will be optimal.

##### Optimality of A*
The idea is we are creating contours who's evaluation functions are below a given value. So we are descending toward the goal.
![[Pasted image 20220126110001.png]]

##### Properties
Note with the [[Asymptotic Analysis]] these are just as bad as the Tree and Graph search algorithms however they on average do better.
**Complete** -> A* is complete unless there are infinitely many nodes with $f\le f(G)$, this can happen when an action has a cost of 0.
**Time-complexity** -> $O(b^m)$ however this is in the worst case.
**Space-complexity**-> $O(b^m)$ again as it is the in the worst case
**Optimality**-> It will always find the optimal solution if the heuristic is **admissible** or if it is **consistent** and we are using graph search.

##### Dominance
If we have two **admissible** heuristic the better one will be the greatest one as it will be able to best approximate the true cost. Better heuristics means far less expansions.

##### Relaxed problems
A problem with fewer restrictions on the actions is called a **relaxed problem**. For example with a tile problem you can just teleport your tile instead of sliding it. Use relaxation to automatically generate admissible heuristics.

[[Informed Search Questions]]

