# Vision
This is our sense to see things very small and close and very large and far away. *Vision* in the brain is very complicated however and almost half of our brain focuses on vision. We detect objects from the almost random stream of photons into our eyes.

### Properties of Vision
Our vision gives us the ability to **detect**, **process** and **interpret** information from visible light to build a representation of the world around us. This begins with the reception and detection of light by a special structure called the *retina*. This information is then transmitted through the *optic nerve* deeper into the brain to an area called the *Thalamus* to begin to be sorted.

![[Pasted image 20220621195742.png]]

From the *Thalamus* the information is further transmitted to the *visual cortex*. The *visual cortex* extracts a lot of information such as **shape**, **color**, **object identify**, **distance**, **motion** and so on.

![[Pasted image 20220621202011.png]]

Inside the *visual cortex* the processing is both *sequential* and *parallel*. The information forks into multiple processing streams each extracting a bit of meaning (information). This is all passed along and processed until the information is extracted to form a complex scene.

### The Nature of Light
We need to understand how light works first. *Light* is a kind of electromagnetic radiation . This whole spectrum includes other forms like microwaves, radio waves, and x-rays. Each type is categorized by a specific part of the spectrum define by the **wavelength** of each kind of wave. 

![[Pasted image 20220621202327.png]]

Between Microwave and X-ray we call the EM light although above 700nm we call it infrared which we cannot see and bellow 390nm ultraviolet. We see **visible light** from (390nm - 700nm) giving us our spectrum from violet to red. Light is very fast traveling $3\cdot10^8ms^{-1}$ enough to circumnavigate the globe around 7 times a second. Compared to our nervous system this transmission is about instantaneous hence why sensing this light is an important sense that almost all animals have providing fast long range detection. Light although it is a wave acts like a particle in some ways and we call this particle a *photon*.

### The Eye
This is where the visual system starts and where all light information originates for us. On the retina there are special *photoreceptor* cells which convert the light energy to action potentials. The *retina* itself already does some image processing before the message is sent down the *optic nerve*. 

![[Pasted image 20220622224919.png]]

The eye itself is moved around by **oculomotor muscles**. This is automated to stabilize the image within the brain. They eyes also rotate to counteract leaning! The eye changes the size of the *pupil* to adapt to different light levels. The eye can clean itself through tears and blinking. There are about 100 million photoreceptors but they are distributed **extremely unevenly**. There are far more photoreceptors in the center of our vision in an area called the *fovea*.

![[Pasted image 20220622225329.png]]

For this reason we have very high resolution in a small part but for the res of our vision we are lacking. We only think we have higher resolution vision since our eye is constantly moving about three times a second on average. Only a million axons carry information away from the retina. Most animals don't have retinas like or however (although *primates* do). Most mammals don't have a high resolution *fovea* while they may have different patterns of high resolution photoreceptors.

The **vertebrate retina** has at least 10 distinct layers. This is simplified into 3 main functional stages. *Photoreception*, *internal transmission* and output.

![[Pasted image 20220623094347.png]]

Strangely this is back to front with *photoreception* furthest away form where the light enters. The initial photoreception takes place with **photoreceptors** which are special kinds of cells. The signals from these are processed by **bipolar cells** and **interneurons** before being further passed onto **retinal ganglion cells** which act as *feature detectors*. At each stage there are *laterally connecting cells* called **Horizontal Cells** and **Amacrine  Cells**. These allow *synchronization* and some *integration* of the input. There are only a few types of photoreceptors but more tan **50** types of interneurons and more than **30** types of retinal ganglion cells identified. This allows for a detailed differentiation and integration of the input signal. The axons from the *retinal ganglion cells* are bundled into the optic nerve. The signal at this point is in the form of parallel action potentials coding for each visual feature detected. These are then sent onto deep brain regions to be processed.

### Phototransduction
This is the process by which light is converted into information. *Photoreceptors* are split into two groups **cones** and **rods**. They all have the same basic structure with an *outer segment*, *inner segment* and *synaptic terminal*.

![[Pasted image 20220623095708.png]]

**Rods** allow of low light processing while **cones** allow for color perception. Our eyes also don't capture information in absolute terms. This is why a camera's sunset is different to the ones we see. The number of different colors and level we see is called *dynamic range*. Our dynamic range.

##### Photoreceptor innerworkings
This process involved the transfer of energy from *electromagnetic* to *chemical* to *electrical* in a chemical cascade. This is called **photoreception**. In the outer segment the *photons* are converted to *chemical energy* this is later converted to *electrical* in the inner segment. Then at the synaptic terminal a *chemical* signal is again created from the electrical one. All our senses evolved to transduce sensations into electrical signals as this is what is used by the nervous system to communicate.

![[Pasted image 20220623100236.png]]

We will start by looking at **rods** which outnumber **cones** about 20:1. Most of rod phototransduction also applied to cones. In the nervous system information is the flow of membrane potential changes in neurons. *Phototransduction* can convert light energy into changes in membrane potential in the **photo receptor cell**. This is analogous to the conversion of *chemical* to *electrical* signals during synaptic transmission. The difference is instead of reacting to a chemical ligand *photoreceptors* react to **electromagnetic energy**. This will not be delved into for now but some chemicals change shape when they experience certain light frequencies. In rods a chemical signal is accomplished through a proteins called *rhodopsin*. This is a membrane protein localized to the *disks* in the outer segment of the photo receptor. It is made up of a GPCR called **opsin** and its ligand **retinal** giving the *visual pigment* its name. *Retinal* is also called *retinaldehyde* and is one of the many forms of **Vitamin A**. Hence why vitamin A deficiency leads to blindness. The GPCR stimulates the downstream enzymatic generation of cytoplasmic second messenger molecules. These *second messenger molecules* can then change indirectly or directly change conductance of ion channels then changing neuronal potential. The strangeness with rhodopsin is the ligand retinal is already tightly bound to the GPCR opsin. When a photon hits the retinal it changes from 11-cis retinal to all-trans retina. Where cis and trans refers to the relative position of the side chains. This change in **retinal** causes changes in the **opsin** backbone. The GPCR pathway is then similar to before with G-protein *transducin* being activated this then affects concentrations of second messengers proteins like cGMP by an enzyme called *phosphodiesterase* this leads to the modulation of cGMP-gated ion channels changing membrane potential.

In he absence of light *cGMP* normally opens sodium and calcium conducting ion channels in the outer segment of the photo receptor depolarizing the cell after sodium influx. Light in fact *depletes* **cGMP** closing the ion channels and hyperpolarizing the cell. Hence neurotransmitter is released when its dark and not released when its light. The only light dependent part in the conversion from 11-cis retinal to all-trans retinal. Only one photon is needed for this conversion to be made. The amplification cuased by using a biochemical cascade is what allows for even small light level to be seen. 

![[Pasted image 20220623103948.png]]

### Color Vision
The primary principles of phototransduction also apply to **cones** which are responsible for color vision and eye sensitivity. They are also able to see *finer detail* and *more rapid changes*. Each cone is generally one of three types, each has a different visual pigment sensing different wavelengths of light. *Short wave cones* or **S-cones** detect blue light with a peak wavelength from around 420 to 440 nm. *Middle wave cones* or **M-Cones** detect green light with a peak from 535-550 nm. Then *Long wave cones* or **L-cones** detect red light with a peak form 565 - 580 nm. In comparison **rod cells** have a peak around 498 nm about half way in-between short and middle. All cone receptors type contain a GPCR protein called *photopsin* also known as *cone-opsin*. This achieves light transduction in a similar manner to rods with the conversion of 11-cis retinal to all-trans retinal. But the photopsin differs by a few amino acids for each cone type, giving light absorption at different wavelengths. But how can we see a range of colors with only red, green and blue. These curves a spread our and overlap so a relative color range from each receptor is all that is needed. This is called *trichromat* or three color vision.

![[Pasted image 20220623120912.png]]

Each combination if light coming in gives a different relative activation this also means different spectrum will look the same color hence why a RGB screen can give all different colors. These spectrum giving the same color are called *metamers*.

![[Pasted image 20220623121058.png]]

There are animals and even some people that are **tetrachromats** and can see with four cones. We would have to stimulate each of the the same amount to give the same color. Color blindness is caused by one of the cones not being able to work properly. For example when the S cone's GPCR proteins are mutated to failure. Cones aren't sensitive to dim light so in the night our color vision goes away this is called **scotopic vision** in the day our rods are bleached and cones are active so we see color this is called *photopic vision*.

### Retinal Processing
There are many cells in the retina processing signals such as bipolar cells, interneurons, horizontal cells, amacrine cells but **retinal ganglion cells** are the only ones that can create *action potentials*. All the others respond with membrane changes only (accept maybe amacrine cells). Its far harder to detects action potentials than membrane potentials hence why *ganglion cell's* processing was understood first. In the original experiments an animal as euthanatized and retinal cells were linked up to electrodes. Different cells were then compared to images shows on a screen to the animals giving the **receptive field** (area activating each ganglion cell) of each neuron. It was found that a receptive field for ganglion cells was in a *center*-*surround* organization. When a center was illuminated an action potential was seen but this effect was abolished when part or all of the surround was also also illuminated. These are called **on-center** cells but there are also **off-center** cells working in the opposite way. Later is was shown in the 1970s that the upstream bipolar and horizontal cells lead to this effect. We know know each photoreceptor can be part of the center and surround of a receptive field for different retinal ganglion cells with the action of the lateral pathways for example amacrine cells responsible for the center surround organization. So most **ganglion cells** respond to *small spots* of light rather than large ones. This center-surround organization of the receptive field is thought to lead to higher sensitivity to edges and contrast.

### The Retinal Circuit
The most direct path of information flow in the retinal is from an *input* to a *photoreceptor* through a *bipolar cell* to an output *retinal ganglion cell*. This is known as the **direct pathway**. At each pathway in between the connections are modulated by *horizontal* and *amacrine* cells this is called the **lateral pathway**. The retina is part of the CNS so the main neurotransmitter used is the amino acid *glutamate*. **Photoreceptors** are depolarized in the dark and hyperpolarized in the light (reverse of what you'd expect). So seeing a shadow depolarizes. Each **photoreceptor** is in contact with bipolar and lateral cells so the information can flow in the *direct* and *lateral* pathways.

##### Direct Pathway
Based on the responses to glutamate released by photoreceptors we can classify *bipolar cells* as either **on** or **off** cells. In **off** bipolar cells glutamate-gated ion channels mediate depolarizing excitatory postsynaptic potential (EPSP) after sodium influx. In **on** bipolar cells GPCR receptors hyperpolarize in response to glutamate. Hence **off** cells react quicker **on** slower. **Off** produce excitation when dark is sensed and **on** in reverse when light is sensed or a lack of dark. Hence the names come from flipping the since the photoreceptor signals are already flipped from normal convention. So this comes from when they *depolarize* when light is on (more glutamate) or when light is off (less glutamate). Each **bipolar cell** receives direct synaptic input from a cluster of *photoreceptors* ranging from one to thousands in number. Each **bipolar cell** is also connected via *horizontal cells* to a ring of *photoreceptors* around the direct cluster.

![[Pasted image 20220623130607.png]]

Hence giving us the who regions the *direct* center path and *surround* lateral path. Generally the response to the *center* is **opposite** to the *surround*.

![[Pasted image 20220623130811.png]]

The *antagonistic surround* is thought to come from a complex interaction between horizontal cells, photoreceptors, bipolar cells and their synapses but is still in active research. Synapses in the **ganglion cells** takes the center surround organization from the bipolar cells integrating rod and cone inputs is modulated by amacrine cells also plays a role. There are about 1 million *retinal ganglion cells* in the retina and receive their *on* or *off* input from the corresponding bipolar cells. Thus an ON center retinal ganglion cell will be **depolarized** most when the center is illuminated and the edge is dark hence firing the most action potentials. Then an OFF center will respond to a dark spot and a bright surround.

Not all *retinal ganglion cells* have a simple center-surround receptive fields. Some RGCs response to particular colors or movements of light patters across local regions f the retina. This comes from diversity in the response properties of different connectivity patterns above different classes of *amacrine* and *bipolar cells*. Since we know there are about 30 different **amacrine** cells and a dozen **bipolar** cells this allows for a large number of possible combinations selecting for specific features. We still do not know all the different *ganglion cells* and we don't know what these kinds of cells are for why is it processed here and not somewhere else. Some research suggests these cells perform a role in the *optic kinetic reflex* which moves the eye to stabilize the image.

### The Retinofugal Projection
First to orient in the brain *dorsal* is like top just as we have a dorsal fin on a shark, *ventral* inversely means bottom. Front is then *anterior* and back is *posterior*.

After leaving the retina the axons go many places. The pathways that leave the eye beginning with the optic nerve are collectively referred to as the **Retinofugal pathway**. Which translates as fleeing the retina. A significant subset of retinal *projections* go to a structure called the *tectum* or *colliculus* which is a low level brain structure sitting above the brainstem. So this is called the **retinotectal projection**.

![[Pasted image 20220624170328.png]]

The tectum is a ancient structure present in many other creatures and involved in orienting to stimuli and the environment. When something suddenly appears in the environment and we involuntarily move our eye towards it this is the *tectum*. Other retinal axon go to other smaller nuclei such as the **accessory optic system** which is involved in  involuntary reflexes like the optokinetic reflex acting like vibration reduction on a camera lens. Another major projection goes to the **thalamus** in the middle of the brain before being projected further to the *cerebral cortex* (which is the folded matter involved in higher level cognition). Most of conscious vision occurs in the **visual cortex**.

![[Pasted image 20220624170805.png]]

We can follow the path from the eye to the midbrain to the *visual cortex*. The **Retinofugal projection** has five major parts before reaching the *visual cortex*. In order these are *the optic nerve*, *optic chiasma*, *optic tract*, *lateral geniculate nucleus* and *optic radiation*.

![[Pasted image 20220624171009.png]]

The **optic nerve** is a bundle of nerves destined for the visual cortex. The input from the left visual field is destined for the right hemisphere and the left the other way around. Nerves cross from right to left in order so that they will be present on the right side. This happens with *half retinas* (hemiretina) so that the visual system is correctly split. This crossing happens in a structure called the **optic chiasma** where nerves from both eyes combine. The crossing of a bundle of fibers from ones side of the brain to the other is called a *decussation*. Following *decussation* at the optic chiasma the axons of the Retrofugal projections form the **optic tracts** which on each side of the brain follow into a specialized structure in the *thalamus* called the **Lateral geniculate nucleus** (LGM). From the **LGM** the path continues in the right and left hemisphere via the **optic radiations** to the right and left **visual cortex**. Which is the central processing area of most visual information.

### Lateral Geniculate Nucleus
This is located in the *dorsal lateral* part of the thalamus (above the brainstem between the cortex and the midbrain). The function of the LGN is matter of research but some is known. The right LGN processed information from the left and the right LGN processes information from the left. The *ipsilateral* and *contra-lateral* axons from the retina projects each into three distinct layers so six in total. These encode three functional streams of information. The most ventral layers contain larger neuron (**magnocellular**, *m-type* neurons). The four dorsal layers contain smaller neurons (**parvocellular**, *p-type* neurons). Then between each layer there are additional neurons called **koniocellular** neurons. The cells are in innervated by axons from *retinal ganglion cells* giving an example of **parrallel processing**.

![[Pasted image 20220624214623.png]]

The receptive fields of these neurons in the **LGN** are similar to those in the retina which makes sense as only a few retinal ganglion cells innervate each LGN neuron. **Magnocellular** neurons display *large* center surround receptive fields and show burst transiently in response to *moving objects*. **Parvocellular** neurons displays *small* center surround receptive fields and give sustained firing in response to object shape. Finally *koniocellular* neurons appear to be involved in representing certain color information. Axons from the LGN neurons project onwards to the primary visual cortex. But the *retina* isn't the main source of synaptic input to the LGN 80% of excitatory synapses found come from the visual cortex, although this is poorly understood. The rhythmic activity coming from **thalamocortical loops** helps give rise to some rhythmic brainwave features measured in EEG.

### Primary Visual Cortex: V1
From the **LGN** information continues via the *optic radiations* to the visual cortex. The *cortex* is a folded layer of tissue covering the *cerebrum*. It is fundamentally a 2D structure like a crumped pieces of paper lining the brain. The cortical sheet is *laminar* in structure meaning composed of sheets. There are six in most parts of the cortex. The cortex is about two millimeters thick in humans and each layer is composed of different cell types. The *visual portion* of the cortex begins at the back of the brain in the *occipital lobe* and extends into the *temporal* and *parietal cortices*. The **primary visual cortex** is the first area to receive information from the LGN axons. This is located right at the back of the brain in a deep fold in the cortical surface called the **calcarine sulcus**.

![[Pasted image 20220624220139.png]]

This area is also called **V1** for visual area one and *striate cortex* based on the appearance of a dark stripe called the *stria of Gennari* which is visible in a sliced up brain. This dark strip is in layer 4 of cortex where all the **LGN** axons innervate the cortical sheet. The axons from the LGN innervate cortex in a orderly fashion preserving spatial x,y organization of the retina in spatial dimensions of the 2D cortical sheet. This orderly pattern of connections is called *Retinotopy*.

![[Pasted image 20220624220509.png]]

Unlike the LGN where every layer gets incoming neural input from the retina and sends outgoing axons to the cortex, in the *primary visual cortex* it arrives specific layers of the structure. The **largest** input occurs in the spiny stellate neurons in layer 4. This includes information from the *magnocellular* and *parvocellular* neurons in the **LGN**. Where are LGN inputs in layers 2 and 3 come primarily from *koniocellular* neurons. The inputs from the left and right eyes remains segregated in the *ocular dominance columns* or *ODCs*. These are stripes of neurons which respond preferentially to inputs from one eye over the other. These columns pan multiple cortical layers and are laid out in a striped pattern across the surface of V1.

![[Pasted image 20220624220821.png]]

The *ODCs* where very important in early studies of cortical plasticity. It was discovered that *monocular deprivation* that is patching one eye during development causes specific columns to degrade while the non deprived eye assumed control over the cortical cells.

### Physiology of Area V1
Receptive fields in the LGN and V1 were mapped out. They key to allowing this was a novel method for measuring neurons activity. This was the *tungsten microelectrode* which is a think wire insulated along its length and sharpened at its tip down to the wide of a neuron. Hence the activity of single neurons in the vicinity other micro electrode could be measured, The electrode doesn't pierce the membrane so only *extracellular potentials* are measured. In **layer 4** of **V1** it was found that receptive fields matches center surround organization of *retinal ganglion cells*. That is light or dark stops excited the neurons and the revers inhibited. The **layer 4** inputs are also monocular so this is all similar to the retina. It was then found by chance that outside **layer 4** more complex shapes like lines were responsible for excitation and inhibition. With the *movement* of the line also affecting the activation. These are called **V1** edge detectors and they determine if edges are present in a region aswell as their movement across space. We also find the first *binocular vision* incorporating information from both eyes in **V1**. But still one eyes may often dominate giving *ocular dominance*. This has a *columnar organization* meaning patches of cortex break up these patterns spatially. This is maintained throughout the laminar depth 

![[Pasted image 20220625094615.png]]

If an animal has its vision patched at birth the organization of ODCs changes massively, the columns for the occluded eye fail to emerge. This has lead to *ocular dominance* being a key area of study to show how the cortex develops.

### Visual Pathways
Once information reaches the visual cortex it starts in **V1** at first the simples features are detected (points areas), this gets more complex to lines, colors and movement and as the information moves through the brain *more complex features* are build up and identified. **V1** is in the posterior lobe but as the information spreads out from here different areas fucus on different features. The information is processed *sequentially* and in *parallel*. There is a series of pathways going up the *dorsal* and one going down to the *ventral* each leading to the other sequentially. These are called the **dorsal pathway** and **ventral pathway**. The dominant flow is sequential and isolated but large amounts of information are exchanged between the two systems. We can take a tour of what is processed along the pathways.

##### Ventral Pathway
The information starts in **V1** we then  move to **V2** just Infront of *V1*. From *V2* we move to **V4** which lies on the ventral surface. Then in primates an to an area called the **inferior temporal cortex** this is called area **IT**. In humans this is roughly the bottom of the brain. As we move between the areas patters can be seen. 

**Size** -> In *V1* the receptive fields are small but as we move along the areas the size grown and they can be very large for *IT*. So cells here may respond to information perhaps anywhere in the visual field.

**Complexity** -> We also find a gain in complexity. In *V1* we find areas which respond to small edges and areas but as we move along to *V2* we find responses to larger lines and contours. In *V4* we find selectivity for curvature like corners and so forth. In *IT* we find responses to entire object for example faces or particular view of faces.

Due to this seeming to build up a view of what is in the world the *ventral visual pathway* is also called the **"what" pathway**.

##### Dorsal Pathway
This contrasts with the *ventral pathway* and is instead focused on **where** things are and **how** we should interact with them. This pathway has areas like the **middle temporal area** or **MT** which seems to encode movement like an object moving through the visual field. These are in fact tuned for direction and velocity. There is the **posterior parietal area** in which we find neurons tuned to specific areas in visual space.

### Lesions of the Visual Cortex
This is one of the ways what parts of the brain do what is found out. We look at what happens when parts are damage and what *functionality is lost*. **Lesions** come in two types there are *experimental* studies where the researchers damage specific parts of the brain to see what happens. They can be *permanent* (when the tissue is suctioned out or chemically damaged) or they can be *temporary*. These can be induced by drugs or by using **optogenetics** where neurons are made sensitive to light then shining light on them can cause loss of functionality. In the human brain we study **observed** lesions which can come from many causes like *disease*, *stroke* and *injury* (concussions and bullets).

Small lesions in **V1** will cause a *scotoma* as this part of the cortex is still laid our with respect to the visual fields this will cause a blind spot. *Scotomas* can also exits in **V2**. In later areas lesions can lead to classes of objects not being recognized. These are called **agnosias**. There are different types like for some people they cannot recognize objects and other cannot recognize faces (called *prosopagnosia*, face blindness).

In the *dorsal pathway* we get different deficiencies from lesions. For example *akinetopsia* or motion blindness. These people can see the world around them but cannot process motion. So the world is a series of frames instead of a fluid world. When the *parietal cortex* is lesioned you can get *visual neglect* as this area is involved in moving are attention from one area to another. So people with this may only eat half a plate and the other half is ignored. Damage to both hemispheres of the *parietal cortex* can give **Balint's syndrome** which can result in *simultaneal* shown by an inability to direct attention anywhere in the visual field and an inability to experience the world as a whole and not a series of parts.

### The Binding Problem
In the brain so far we have broken apart the visual world into its parts. But how can this information be brought back together to give a entire understanding of the world. This is called the **binding problem** and it unsolved. We cannot have a series of neurons for each possible commination of attributes as this would lead to a *combinatorial explosion*. Instead it has been proposed that *synchronous firing* may lead to tagging. But many other solutions have been proposed.