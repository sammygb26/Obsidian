We will continue to look at the kinds of harm (on top of proof bias and fairness). This can be hard to quantify hence is hard to CS people. In general we create automated system that replace people. There may  be many way to do things with computers but they all replace the existing method **people**.

All the things we optimize for are things easily measured. Then we develop computer solutions to solve this problem. When these measures guide us anything people already do better wont be represented hence it is biased against people.

## Keeping People Involved

**Humans as robustness** - We know that machines are only designed for one task hence if somethings changes they can break. Humans can adapt on the fly quickly and so can solve new data.

This is similar to **trust**, we don't trust robots since they can always fail where as we know a human is able to adapt and therefore we trust them more.

**Humans as value** - here humans just being humans is a benefit. For example automated helplines work much worse than staffed ones. Hence a lot of technologies cut out humans and so we don't get any social benefit form these systems.

**Humans as benefactors** - Here the worker gets benefit from doing the work aswell. For example people benefit form having jobs they enjoy and feel good doing. We can think also about the trade-offs of our metrics. By optimizing for them we may create a world which we don't even enjoy.